{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChjuaQjm_iBf"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:28.506274Z",
     "iopub.status.busy": "2022-01-28T12:13:28.505566Z",
     "iopub.status.idle": "2022-01-28T12:13:28.508705Z",
     "shell.execute_reply": "2022-01-28T12:13:28.508099Z"
    },
    "id": "uWqCArLO_kez"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikhIvrku-i-L"
   },
   "source": [
    "# Taking advantage of context features\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/context_features\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/context_features.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/context_features.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/context_features.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrDVNe7Vdqhr"
   },
   "source": [
    "In [the featurization tutorial](featurization) we incorporated multiple features beyond just user and movie identifiers into our models, but we haven't explored whether those features improve model accuracy.\n",
    "\n",
    "Many factors affect whether features beyond ids are useful in a recommender model:\n",
    "\n",
    "1. __Importance of context__: if user preferences are relatively stable across contexts and time, context features may not provide much benefit. If, however, users preferences are highly contextual, adding context will improve the model significantly. For example, day of the week may be an important feature when deciding whether to recommend a short clip or a movie: users may only have time to watch short content during the week, but can relax and enjoy a full-length movie during the weekend. Similarly, query timestamps may play an important role in modelling popularity dynamics: one movie may be highly popular around the time of its release, but decay quickly afterwards. Conversely, other movies may be evergreens that are happily watched time and time again.\n",
    "2. __Data sparsity__: using non-id features may be critical if data is sparse. With few observations available for a given user or item, the model may struggle with estimating a good per-user or per-item representation. To build an accurate model, other features such as item categories, descriptions, and images have to be used to help the model generalize beyond the training data. This is especially relevant in [cold-start](https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)) situations, where relatively little data is available on some items or users.\n",
    "\n",
    "In this tutorial, we'll experiment with using features beyond movie titles and user ids to our MovieLens model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7RYXwgbAcbU"
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "We first import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:28.519354Z",
     "iopub.status.busy": "2022-01-28T12:13:28.516438Z",
     "iopub.status.idle": "2022-01-28T12:13:31.704513Z",
     "shell.execute_reply": "2022-01-28T12:13:31.703943Z"
    },
    "id": "2bK2g6_Mbn73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylint 2.12.2 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "astroid 2.9.0 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.24.25 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmleYcLHAnkm"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:31.710116Z",
     "iopub.status.busy": "2022-01-28T12:13:31.709480Z",
     "iopub.status.idle": "2022-01-28T12:13:34.128886Z",
     "shell.execute_reply": "2022-01-28T12:13:34.128267Z"
    },
    "id": "XbwMjnLP5nZ_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgKIjpQLAiax"
   },
   "source": [
    "We follow [the featurization tutorial](featurization) and keep the user id, timestamp, and movie title features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:34.134984Z",
     "iopub.status.busy": "2022-01-28T12:13:34.134268Z",
     "iopub.status.idle": "2022-01-28T12:13:38.922875Z",
     "shell.execute_reply": "2022-01-28T12:13:38.923336Z"
    },
    "id": "kc2REbOO52Fl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 4.70 MiB (download: 4.70 MiB, generated: 32.41 MiB, total: 37.10 MiB) to /home/ec2-user/tensorflow_datasets/movielens/100k-ratings/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ed4396b9f44f8087b972a3ae1e7189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55afdee3bb5b46a6a5a1f6b35535a895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84de3a4ea7e64d3db3a03aa6d822c09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/ec2-user/tensorflow_datasets/movielens/100k-ratings/0.1.0.incomplete78PIWE/movielens-train.tfr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /home/ec2-user/tensorflow_datasets/movielens/100k-ratings/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[1mDownloading and preparing dataset 4.70 MiB (download: 4.70 MiB, generated: 150.35 KiB, total: 4.84 MiB) to /home/ec2-user/tensorflow_datasets/movielens/100k-movies/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5beecc3b742242beb51e5349e02dacc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12af28af9d3401f8e1a89d6fba015a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62c8a8712e94fd0b95a50aab8cb0195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/1682 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/ec2-user/tensorflow_datasets/movielens/100k-movies/0.1.0.incomplete32LLY1/movielens-train.tfre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /home/ec2-user/tensorflow_datasets/movielens/100k-movies/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"timestamp\": x[\"timestamp\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>sample_prob</th>\n",
       "      <th>train_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...</td>\n",
       "      <td>0673531001</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...</td>\n",
       "      <td>0464277014</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...</td>\n",
       "      <td>0464277014</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id  \\\n",
       "0  2018-09-20  002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...  0673531001   \n",
       "1  2018-09-20  002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...  0464277014   \n",
       "2  2018-09-20  002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...  0464277014   \n",
       "\n",
       "      price  sales_channel_id  sample_prob  train_test  \n",
       "0  0.008458                 2      0.05903           0  \n",
       "1  0.022017                 2      0.05903           0  \n",
       "2  0.022017                 2      0.05903           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "masterdf = pd.read_csv('s3a://hluan/hm/sampled_10_users_transactions.csv', dtype={\"article_id\": \"str\"})\n",
    "masterdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "masterdf['t_dat'] = pd.to_datetime(masterdf['t_dat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf['t_dat'] = datetime(2020, 9, 22) - masterdf['t_dat']\n",
    "masterdf['t_dat'] = (masterdf['t_dat'].dt.days / 7).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_part = masterdf[['t_dat', 'customer_id', 'article_id', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...</td>\n",
       "      <td>0673531001</td>\n",
       "      <td>0.008458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...</td>\n",
       "      <td>0464277014</td>\n",
       "      <td>0.022017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...</td>\n",
       "      <td>0464277014</td>\n",
       "      <td>0.022017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>005c9fb2ba6c49b2098a662f64a9124ef95cbec5fcf4eb...</td>\n",
       "      <td>0625939005</td>\n",
       "      <td>0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>005c9fb2ba6c49b2098a662f64a9124ef95cbec5fcf4eb...</td>\n",
       "      <td>0508184020</td>\n",
       "      <td>0.024136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_dat                                        customer_id  article_id  \\\n",
       "0    104  002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...  0673531001   \n",
       "1    104  002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...  0464277014   \n",
       "2    104  002b3c0a44a22c45a8d62ea9d2b88d1a89e335f8b84003...  0464277014   \n",
       "3    104  005c9fb2ba6c49b2098a662f64a9124ef95cbec5fcf4eb...  0625939005   \n",
       "4    104  005c9fb2ba6c49b2098a662f64a9124ef95cbec5fcf4eb...  0508184020   \n",
       "\n",
       "      price  \n",
       "0  0.008458  \n",
       "1  0.022017  \n",
       "2  0.022017  \n",
       "3  0.003373  \n",
       "4  0.024136  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "master_df_part['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define interactions data and user data\n",
    "\n",
    "### interactions \n",
    "### here we create a reference table of the user , item, and quantity purchased\n",
    "interactions_dict = master_df_part.groupby(['customer_id', \n",
    "                                      'article_id',\n",
    "                                      't_dat'])[['rating', 'price']].sum().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00018385675844f7a6babbed41b5655b5727fb16483b6e...</td>\n",
       "      <td>0535455002</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018385675844f7a6babbed41b5655b5727fb16483b6e...</td>\n",
       "      <td>0616849012</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00018385675844f7a6babbed41b5655b5727fb16483b6e...</td>\n",
       "      <td>0621020001</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00018385675844f7a6babbed41b5655b5727fb16483b6e...</td>\n",
       "      <td>0626813002</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00018385675844f7a6babbed41b5655b5727fb16483b6e...</td>\n",
       "      <td>0626813004</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841724</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>0832321002</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841725</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>0832520001</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841726</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>0835008005</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841727</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>0840567001</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841728</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>0860949003</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2841729 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_id  article_id  t_dat  \\\n",
       "0        00018385675844f7a6babbed41b5655b5727fb16483b6e...  0535455002     99   \n",
       "1        00018385675844f7a6babbed41b5655b5727fb16483b6e...  0616849012     99   \n",
       "2        00018385675844f7a6babbed41b5655b5727fb16483b6e...  0621020001    103   \n",
       "3        00018385675844f7a6babbed41b5655b5727fb16483b6e...  0626813002     99   \n",
       "4        00018385675844f7a6babbed41b5655b5727fb16483b6e...  0626813004     99   \n",
       "...                                                    ...         ...    ...   \n",
       "2841724  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...  0832321002     13   \n",
       "2841725  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...  0832520001     26   \n",
       "2841726  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...  0835008005     26   \n",
       "2841727  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...  0840567001     15   \n",
       "2841728  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...  0860949003     13   \n",
       "\n",
       "         rating     price  \n",
       "0             1  0.020322  \n",
       "1             1  0.008458  \n",
       "2             1  0.033881  \n",
       "3             1  0.008458  \n",
       "4             1  0.008458  \n",
       "...         ...       ...  \n",
       "2841724       1  0.016932  \n",
       "2841725       1  0.025407  \n",
       "2841726       1  0.045746  \n",
       "2841727       1  0.030492  \n",
       "2841728       1  0.025407  \n",
       "\n",
       "[2841729 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_dict = interactions_dict[interactions_dict['t_dat'] <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = \"\"\n",
    "customers = pd.read_csv(f'{input_data_path}customers.csv', dtype={\"article_id\": \"str\"})\n",
    "articles = pd.read_csv(f'{input_data_path}articles.csv', dtype={\"article_id\": \"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['product_group_code'] = articles['product_group_name'].astype('category').cat.codes\n",
    "articles['index_code_id'] = articles['index_code'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['color-code'] = articles['colour_group_code'].astype('str') + articles['perceived_colour_value_id'].astype('str') \\\n",
    "    + articles['perceived_colour_master_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          945\n",
       "1         1039\n",
       "2         1119\n",
       "3          945\n",
       "4         1039\n",
       "          ... \n",
       "105537     945\n",
       "105538     945\n",
       "105539     945\n",
       "105540     945\n",
       "105541    1119\n",
       "Name: color-code, Length: 105542, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['color-code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'product_code', 'prod_name', 'product_type_no',\n",
       "       'product_type_name', 'product_group_name', 'graphical_appearance_no',\n",
       "       'graphical_appearance_name', 'colour_group_code', 'colour_group_name',\n",
       "       'perceived_colour_value_id', 'perceived_colour_value_name',\n",
       "       'perceived_colour_master_id', 'perceived_colour_master_name',\n",
       "       'department_no', 'department_name', 'index_code', 'index_name',\n",
       "       'index_group_no', 'index_group_name', 'section_no', 'section_name',\n",
       "       'garment_group_no', 'garment_group_name', 'detail_desc',\n",
       "       'product_group_code', 'index_code_id', 'color-code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_processed = articles[['article_id', \n",
    "       'prod_name', \n",
    "       'product_type_name', 'product_group_name', \n",
    "       'graphical_appearance_name', 'colour_group_name',\n",
    "       'perceived_colour_value_name',\n",
    "       'perceived_colour_master_name',\n",
    "       'department_name', 'index_name',\n",
    "       'index_group_name', 'section_name',\n",
    "       'garment_group_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 35, 45, 55, 120]\n",
    "labels = [1,2,3,4]\n",
    "customers['age_group'] = pd.cut(customers['age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_dict = interactions_dict[['t_dat', 'customer_id', 'article_id', 'rating', 'price']]\\\n",
    "    .merge(articles_processed, on='article_id', how='left')\\\n",
    "    .merge(customers[['customer_id', 'age_group']], on='customer_id', how='left')\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions_dict['section_no'] = interactions_dict['section_no'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2841729 entries, 0 to 2841728\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Dtype   \n",
      "---  ------                        -----   \n",
      " 0   t_dat                         int64   \n",
      " 1   customer_id                   object  \n",
      " 2   article_id                    object  \n",
      " 3   rating                        int64   \n",
      " 4   price                         float64 \n",
      " 5   prod_name                     object  \n",
      " 6   product_type_name             object  \n",
      " 7   product_group_name            object  \n",
      " 8   graphical_appearance_name     object  \n",
      " 9   colour_group_name             object  \n",
      " 10  perceived_colour_value_name   object  \n",
      " 11  perceived_colour_master_name  object  \n",
      " 12  department_name               object  \n",
      " 13  index_name                    object  \n",
      " 14  index_group_name              object  \n",
      " 15  section_name                  object  \n",
      " 16  garment_group_name            object  \n",
      " 17  age_group                     category\n",
      "dtypes: category(1), float64(1), int64(2), object(14)\n",
      "memory usage: 393.0+ MB\n"
     ]
    }
   ],
   "source": [
    "interactions_dict.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                      0\n",
       "prod_name                       0\n",
       "product_type_name               0\n",
       "product_group_name              0\n",
       "graphical_appearance_name       0\n",
       "colour_group_name               0\n",
       "perceived_colour_value_name     0\n",
       "perceived_colour_master_name    0\n",
       "department_name                 0\n",
       "index_name                      0\n",
       "index_group_name                0\n",
       "section_name                    0\n",
       "garment_group_name              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_processed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_dict['age_group'] = interactions_dict['age_group'].fillna(1)\n",
    "# interactions_dict['detail_desc'] = interactions_dict['detail_desc'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n",
    "ratings = tf.data.Dataset.from_tensor_slices(interactions_dict)\n",
    "\n",
    "# movies_dict = articles_processed.map(lambda x: x[\"article_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {t_dat: (), customer_id: (), article_id: (), rating: (), color-code: (), detail_desc: (), section_no: (), age_group: ()}, types: {t_dat: tf.int64, customer_id: tf.string, article_id: tf.string, rating: tf.int64, color-code: tf.string, detail_desc: tf.string, section_no: tf.int64, age_group: tf.int64}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles_processed['detail_desc'] = articles_processed['detail_desc'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "items_dict = {name: np.array(value) for name, value in articles_processed.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {t_dat: (), customer_id: (), article_id: (), rating: (), price: (), prod_name: (), product_type_name: (), product_group_name: (), graphical_appearance_name: (), colour_group_name: (), perceived_colour_value_name: (), perceived_colour_master_name: (), department_name: (), index_name: (), index_group_name: (), section_name: (), garment_group_name: (), age_group: ()}, types: {t_dat: tf.int64, customer_id: tf.string, article_id: tf.string, rating: tf.int64, price: tf.float64, prod_name: tf.string, product_type_name: tf.string, product_group_name: tf.string, graphical_appearance_name: tf.string, colour_group_name: tf.string, perceived_colour_value_name: tf.string, perceived_colour_master_name: tf.string, department_name: tf.string, index_name: tf.string, index_group_name: tf.string, section_name: tf.string, garment_group_name: tf.string, age_group: tf.int64}>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {article_id: (), prod_name: (), product_type_name: (), product_group_name: (), graphical_appearance_name: (), colour_group_name: (), perceived_colour_value_name: (), perceived_colour_master_name: (), department_name: (), index_name: (), index_group_name: (), section_name: (), garment_group_name: ()}, types: {article_id: tf.string, prod_name: tf.string, product_type_name: tf.string, product_group_name: tf.string, graphical_appearance_name: tf.string, colour_group_name: tf.string, perceived_colour_value_name: tf.string, perceived_colour_master_name: tf.string, department_name: tf.string, index_name: tf.string, index_group_name: tf.string, section_name: tf.string, garment_group_name: tf.string}>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = ratings.map(lambda x: {\n",
    "    'customer_id': x['customer_id'], \n",
    "    'age_group': x['age_group'],\n",
    "    'article_id': x['article_id'], \n",
    "    'rating': int(x['rating']),\n",
    "    'price': int(x['price']),\n",
    "    \"t_dat\": x[\"t_dat\"],\n",
    "    \"prod_name\": x['prod_name'],\n",
    "    \"product_type_name\": x['product_type_name'],\n",
    "    \"product_group_name\": x['product_group_name'],\n",
    "    \"graphical_appearance_name\": x['graphical_appearance_name'],\n",
    "    \"colour_group_name\": x['colour_group_name'],\n",
    "    \"perceived_colour_value_name\": x['perceived_colour_value_name'],\n",
    "    \"perceived_colour_master_name\": x['perceived_colour_master_name'],\n",
    "    \"department_name\": x['department_name'],\n",
    "    \"index_name\": x['index_name'],\n",
    "    \"index_group_name\": x['index_group_name'],\n",
    "    \"section_name\": x['section_name'],\n",
    "    \"garment_group_name\": x['garment_group_name'],\n",
    "})\n",
    "\n",
    "articles = items.map(lambda x: x['article_id'])\n",
    "age_group = ratings.map(lambda x: x['age_group'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.map(lambda x:\n",
    "                 {    'article_id': x['article_id'], \n",
    "    \"prod_name\": x['prod_name'],\n",
    "    \"product_type_name\": x['product_type_name'],\n",
    "    \"product_group_name\": x['product_group_name'],\n",
    "    \"graphical_appearance_name\": x['graphical_appearance_name'],\n",
    "    \"colour_group_name\": x['colour_group_name'],\n",
    "    \"perceived_colour_value_name\": x['perceived_colour_value_name'],\n",
    "    \"perceived_colour_master_name\": x['perceived_colour_master_name'],\n",
    "    \"department_name\": x['department_name'],\n",
    "    \"index_name\": x['index_name'],\n",
    "    \"index_group_name\": x['index_group_name'],\n",
    "    \"section_name\": x['section_name'],\n",
    "    \"garment_group_name\": x['garment_group_name'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {customer_id: (), age_group: (), article_id: (), rating: (), price: (), t_dat: (), prod_name: (), product_type_name: (), product_group_name: (), graphical_appearance_name: (), colour_group_name: (), perceived_colour_value_name: (), perceived_colour_master_name: (), department_name: (), index_name: (), index_group_name: (), section_name: (), garment_group_name: ()}, types: {customer_id: tf.string, age_group: tf.int64, article_id: tf.string, rating: tf.int32, price: tf.int32, t_dat: tf.int64, prod_name: tf.string, product_type_name: tf.string, product_group_name: tf.string, graphical_appearance_name: tf.string, colour_group_name: tf.string, perceived_colour_value_name: tf.string, perceived_colour_master_name: tf.string, department_name: tf.string, index_name: tf.string, index_group_name: tf.string, section_name: tf.string, garment_group_name: tf.string}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {article_id: (), prod_name: (), product_type_name: (), product_group_name: (), graphical_appearance_name: (), colour_group_name: (), perceived_colour_value_name: (), perceived_colour_master_name: (), department_name: (), index_name: (), index_group_name: (), section_name: (), garment_group_name: ()}, types: {article_id: tf.string, prod_name: tf.string, product_type_name: tf.string, product_group_name: tf.string, graphical_appearance_name: tf.string, colour_group_name: tf.string, perceived_colour_value_name: tf.string, perceived_colour_master_name: tf.string, department_name: tf.string, index_name: tf.string, index_group_name: tf.string, section_name: tf.string, garment_group_name: tf.string}>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YZ2q5RXYNI6"
   },
   "source": [
    "We also do some housekeeping to prepare feature vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:38.930385Z",
     "iopub.status.busy": "2022-01-28T12:13:38.929591Z",
     "iopub.status.idle": "2022-01-28T12:13:44.176810Z",
     "shell.execute_reply": "2022-01-28T12:13:44.177292Z"
    },
    "id": "G5CVveCS9Doq"
   },
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"t_dat\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=105,\n",
    ")\n",
    "\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(items.batch(1000).map(lambda x: x['article_id']))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"customer_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = np.concatenate(list(ratings.map(lambda x: x[\"price\"]).batch(100)))\n",
    "\n",
    "max_price = price.max()\n",
    "min_price = price.min()\n",
    "\n",
    "price_buckets = np.linspace(\n",
    "    min_price, max_price, num=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'0108775015', b'0108775044', b'0108775051', ..., b'0956217002',\n",
       "       b'0957375001', b'0959461001'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'0003e867a930d0d6842f923d6ba7c9b77aba33fe2a0fbf4672f30b3e622fec55',\n",
       "       b'000b5ee14437ff127c1093eaa2ae3cc8801cfa5dd0b66fd775de26ca7e2265c3',\n",
       "       b'000ee56f745271e72ae8b5680a416a4fbf8acf6a690ab2df92ee58505e6d0136',\n",
       "       ...,\n",
       "       b'fffb287f12aea1204e9eabd5e02eaf7f3ed5f9abecd9a4cb06cd9ecd793a996f',\n",
       "       b'fffd0248a95c2e49fee876ff93598e2e20839e51b9b7678aab75d9e8f9f3c6c8',\n",
       "       b'ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e4747568cac33e8c541831'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t_dat', 'customer_id', 'article_id', 'rating', 'price', 'prod_name', 'product_type_name', 'product_group_name', 'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name', 'index_name', 'index_group_name', 'section_name', 'garment_group_name', 'age_group'])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['prod_name', 'product_type_name', 'product_group_name', 'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name', 'index_name', 'index_group_name', 'section_name', 'garment_group_name', 'age_group']\n",
    "\n",
    "vocabularies = {}\n",
    "\n",
    "for feature_name in feature_names:\n",
    "  vocab = interactions.batch(1_000).map(lambda x: x[feature_name])\n",
    "  vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {article_id: (), prod_name: (), product_type_name: (), product_group_name: (), graphical_appearance_name: (), colour_group_name: (), perceived_colour_value_name: (), perceived_colour_master_name: (), department_name: (), index_name: (), index_group_name: (), section_name: (), garment_group_name: ()}, types: {article_id: tf.string, prod_name: tf.string, product_type_name: tf.string, product_group_name: tf.string, graphical_appearance_name: tf.string, colour_group_name: tf.string, perceived_colour_value_name: tf.string, perceived_colour_master_name: tf.string, department_name: tf.string, index_name: tf.string, index_group_name: tf.string, section_name: tf.string, garment_group_name: tf.string}>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc = items.map(lambda x: x['detail_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_code = items.map(lambda x: x['color-code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_color_code = np.unique(np.concatenate(list(items.batch(1_000).map(\n",
    "#     lambda x: x[\"color-code\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_color_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section = items.map(lambda x: x['section_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {article_id: (), color-code: (), section_no: ()}, types: {article_id: tf.string, color-code: tf.string, section_no: tf.string}>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_section_code = np.unique(np.concatenate(list(items.batch(1_000).map(\n",
    "    lambda x: x[\"section_no\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_section_code = np.array(unique_section_code, dtype='str')\n",
    "# unique_section_code = np.array(unique_section_code, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '4', '5', '6', '8', '11', '14', '15', '16', '17', '18', '19',\n",
       "       '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',\n",
       "       '31', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49',\n",
       "       '50', '51', '52', '53', '55', '56', '57', '58', '60', '61', '62',\n",
       "       '64', '65', '66', '70', '71', '72', '76', '77', '79', '80', '82',\n",
       "       '97'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_section_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFJcCVMUQou3"
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtS6a4sgmI-c"
   },
   "source": [
    "### Query model\n",
    "\n",
    "We start with the user model defined in [the featurization tutorial](featurization) as the first layer of our model, tasked with converting raw input examples into feature embeddings. However, we change it slightly to allow us to turn timestamp features on or off. This will allow us to more easily demonstrate the effect that timestamp features have on the model. In the code below, the `use_timestamps` parameter gives us control over whether we use timestamp features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:44.186885Z",
     "iopub.status.busy": "2022-01-28T12:13:44.186094Z",
     "iopub.status.idle": "2022-01-28T12:13:44.188169Z",
     "shell.execute_reply": "2022-01-28T12:13:44.187686Z"
    },
    "id": "_ItzYwMW42cb"
   },
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self, use_timestamps):\n",
    "        super().__init__()\n",
    "        max_tokens = 10_000\n",
    "        self.embedding_dimension = 32\n",
    "        self._use_timestamps = use_timestamps\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, self.embedding_dimension),\n",
    "        ])\n",
    "        \n",
    "        str_features = []\n",
    "        int_features = ['age_group']\n",
    "        \n",
    "        self._all_features = str_features + int_features\n",
    "        self._embeddings = {}\n",
    "        if use_timestamps:\n",
    "            self.timestamp_embedding = tf.keras.Sequential([\n",
    "              tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "              tf.keras.layers.Embedding(len(timestamp_buckets) + 1, self.embedding_dimension),\n",
    "            ])\n",
    "            self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "              axis=None\n",
    "            )\n",
    "\n",
    "            self.normalized_timestamp.adapt(timestamps)\n",
    "            \n",
    "            self.price_embedding = tf.keras.Sequential([\n",
    "              tf.keras.layers.Discretization(price_buckets.tolist()),\n",
    "              tf.keras.layers.Embedding(len(price_buckets) + 1, self.embedding_dimension),\n",
    "            ])\n",
    "            self.normalized_price = tf.keras.layers.Normalization(\n",
    "              axis=None\n",
    "            )\n",
    "\n",
    "            self.normalized_price.adapt(price)\n",
    "            \n",
    "            for feature_name in str_features:\n",
    "              vocabulary = vocabularies[feature_name]\n",
    "              self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "                  [tf.keras.layers.StringLookup(\n",
    "                      vocabulary=vocabulary, mask_token=None),\n",
    "                   tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                             self.embedding_dimension)\n",
    "            ])\n",
    "\n",
    "            # Compute embeddings for int features.\n",
    "            for feature_name in int_features:\n",
    "              vocabulary = vocabularies[feature_name]\n",
    "              self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "                  [tf.keras.layers.IntegerLookup(\n",
    "                      vocabulary=vocabulary, mask_value=None),\n",
    "                   tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                             self.embedding_dimension)\n",
    "            ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if not self._use_timestamps:\n",
    "            return self.user_embedding(inputs[\"customer_id\"])\n",
    "        embeddings = [\n",
    "            self.user_embedding(inputs[\"customer_id\"]),\n",
    "            self.timestamp_embedding(inputs[\"t_dat\"]),\n",
    "            tf.reshape(self.normalized_timestamp(inputs[\"t_dat\"]), (-1, 1)),\n",
    "            self.price_embedding(inputs[\"price\"]),\n",
    "            tf.reshape(self.normalized_price(inputs[\"price\"]), (-1, 1)),]\n",
    "        for feature_name in self._all_features:\n",
    "            embedding_fn = self._embeddings[feature_name]\n",
    "            embeddings.append(embedding_fn(inputs[feature_name]))\n",
    "        return tf.concat(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9IqNTLmpJzs"
   },
   "source": [
    "Note that our use of timestamp features in this tutorial interacts with our choice of training-test split in an undesirable way. Because we have split our data randomly rather than chronologically (to ensure that events that belong to the test dataset happen later than those in the training set), our model can effectively learn from the future. This is unrealistic: after all, we cannot train a model today on data from tomorrow.\n",
    "\n",
    "This means that adding time features to the model lets it learn _future_ interaction patterns. We do this for illustration purposes only: the MovieLens dataset itself is very dense, and unlike many real-world datasets does not benefit greatly from features beyond user ids and movie titles. \n",
    "\n",
    "This caveat aside, real-world models may well benefit from other time-based features such as time of day or day of the week, especially if the data has strong seasonal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XleMceZNHC__"
   },
   "source": [
    "### Candidate model\n",
    "\n",
    "For simplicity, we'll keep the candidate model fixed. Again, we copy it from the [featurization](featurization) tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:44.195428Z",
     "iopub.status.busy": "2022-01-28T12:13:44.194773Z",
     "iopub.status.idle": "2022-01-28T12:13:44.196448Z",
     "shell.execute_reply": "2022-01-28T12:13:44.196825Z"
    },
    "id": "oQZHX8bEHPOk"
   },
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = 32\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "              vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_titles) + 1, self.embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        str_features = ['prod_name', 'product_type_name', 'product_group_name', 'graphical_appearance_name', \n",
    "                        'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name', \n",
    "                        'index_name', 'index_group_name', 'section_name', 'garment_group_name', ]\n",
    "        int_features = []\n",
    "        \n",
    "        self._all_features = str_features + int_features\n",
    "        self._embeddings = {}\n",
    "        \n",
    "            \n",
    "        for feature_name in str_features:\n",
    "          vocabulary = vocabularies[feature_name]\n",
    "          self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "              [tf.keras.layers.StringLookup(\n",
    "                  vocabulary=vocabulary, mask_token=None),\n",
    "               tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                         self.embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for int features.\n",
    "        for feature_name in int_features:\n",
    "          vocabulary = vocabularies[feature_name]\n",
    "          self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "              [tf.keras.layers.IntegerLookup(\n",
    "                  vocabulary=vocabulary, mask_value=None),\n",
    "               tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                         self.embedding_dimension)\n",
    "        ])\n",
    "    def call(self, inputs):\n",
    "        embeddings = []\n",
    "        embeddings.append(self.title_embedding(inputs['article_id']))\n",
    "        for feature_name in self._all_features:\n",
    "            embedding_fn = self._embeddings[feature_name]\n",
    "            embeddings.append(embedding_fn(inputs[feature_name]))\n",
    "        return tf.concat(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc4KbTNwHSvD"
   },
   "source": [
    "### Combined model\n",
    "\n",
    "With both `UserModel` and `MovieModel` defined, we can put together a combined model and implement our loss and metrics logic.\n",
    "\n",
    "Here we're building a retrieval model. For a refresher on how this works, see the [Basic retrieval](basic_retrieval.ipynb) tutorial.\n",
    "\n",
    "Note that we also need to make sure that the query model and candidate model output embeddings of compatible size. Because we'll be varying their sizes by adding more features, the easiest way to accomplish this is to use a dense projection layer after each model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:44.203575Z",
     "iopub.status.busy": "2022-01-28T12:13:44.199305Z",
     "iopub.status.idle": "2022-01-28T12:13:44.205094Z",
     "shell.execute_reply": "2022-01-28T12:13:44.205469Z"
    },
    "id": "26_hNJPKIh4-"
   },
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "    self.query_model = tf.keras.Sequential([\n",
    "      UserModel(use_timestamps),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.candidate_model = tf.keras.Sequential([\n",
    "      MovieModel(),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=items.batch(128).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    # We only pass the user id and timestamp features into the query model. This\n",
    "    # is to ensure that the training inputs would have the same keys as the\n",
    "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "    # error when loading the query model after saving it.\n",
    "    query_embeddings = self.query_model({\n",
    "        \"customer_id\": features[\"customer_id\"],\n",
    "        \"t_dat\": features[\"t_dat\"],\n",
    "        \"price\": features[\"price\"],\n",
    "        \"age_group\": features['age_group'],\n",
    "    })\n",
    "    movie_embeddings = self.candidate_model(\n",
    "        {\"article_id\": features[\"article_id\"],\n",
    "        \"prod_name\": features['prod_name'],\n",
    "    \"product_type_name\": features['product_type_name'],\n",
    "    \"product_group_name\": features['product_group_name'],\n",
    "    \"graphical_appearance_name\": features['graphical_appearance_name'],\n",
    "    \"colour_group_name\": features['colour_group_name'],\n",
    "    \"perceived_colour_value_name\": features['perceived_colour_value_name'],\n",
    "    \"perceived_colour_master_name\": features['perceived_colour_master_name'],\n",
    "    \"department_name\": features['department_name'],\n",
    "    \"index_name\": features['index_name'],\n",
    "    \"index_group_name\": features['index_group_name'],\n",
    "    \"section_name\": features['section_name'],\n",
    "    \"garment_group_name\": features['garment_group_name'],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return self.task(query_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "    self.query_model = tf.keras.Sequential([\n",
    "      UserModel(use_timestamps),\n",
    "#       tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.candidate_model = tf.keras.Sequential([\n",
    "      MovieModel(),\n",
    "#       tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=items.batch(128).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    # We only pass the user id and timestamp features into the query model. This\n",
    "    # is to ensure that the training inputs would have the same keys as the\n",
    "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "    # error when loading the query model after saving it.\n",
    "    query_embeddings = self.query_model({\n",
    "        \"customer_id\": features[\"customer_id\"],\n",
    "        \"t_dat\": features[\"t_dat\"],\n",
    "        \"price\": features[\"price\"],\n",
    "        \"age_group\": features['age_group'],\n",
    "    })\n",
    "    movie_embeddings = self.candidate_model(\n",
    "        {\"article_id\": features[\"article_id\"],\n",
    "        \"prod_name\": features['prod_name'],\n",
    "    \"product_type_name\": features['product_type_name'],\n",
    "    \"product_group_name\": features['product_group_name'],\n",
    "    \"graphical_appearance_name\": features['graphical_appearance_name'],\n",
    "    \"colour_group_name\": features['colour_group_name'],\n",
    "    \"perceived_colour_value_name\": features['perceived_colour_value_name'],\n",
    "    \"perceived_colour_master_name\": features['perceived_colour_master_name'],\n",
    "    \"department_name\": features['department_name'],\n",
    "    \"index_name\": features['index_name'],\n",
    "    \"index_group_name\": features['index_group_name'],\n",
    "    \"section_name\": features['section_name'],\n",
    "    \"garment_group_name\": features['garment_group_name'],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return self.task(query_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YXjsRsLTVzt"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY7MTwMruoKh"
   },
   "source": [
    "### Prepare the data\n",
    "\n",
    "We first split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:44.212474Z",
     "iopub.status.busy": "2022-01-28T12:13:44.211823Z",
     "iopub.status.idle": "2022-01-28T12:13:44.220452Z",
     "shell.execute_reply": "2022-01-28T12:13:44.221029Z"
    },
    "id": "wMFUZ4dyTdYd"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2HEuTBzJ9w5"
   },
   "source": [
    "### Baseline: no timestamp features\n",
    "\n",
    "We're ready to try out our first model: let's start with not using timestamp features to establish our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:13:44.228697Z",
     "iopub.status.busy": "2022-01-28T12:13:44.226209Z",
     "iopub.status.idle": "2022-01-28T12:14:28.098835Z",
     "shell.execute_reply": "2022-01-28T12:14:28.099250Z"
    },
    "id": "NkoLkiQdK4Um"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'color-code': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'detail_desc': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'section_no': <tf.Tensor 'args_3:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'color-code': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'detail_desc': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'section_no': <tf.Tensor 'args_3:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'color-code': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'section_no': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'color-code': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'section_no': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'color-code': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'section_no': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'color-code': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'section_no': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast int64 to string is not supported\n\t [[node sequential_211/movie_model_29/sequential_210/string_lookup_114/Cast (defined at <ipython-input-276-f4b9da47b25b>:30) ]] [Op:__inference_train_function_398809]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_211/movie_model_29/sequential_210/string_lookup_114/Cast:\n IteratorGetNext (defined at <ipython-input-294-438035174cc8>:4)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-294-438035174cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m train_accuracy = model.evaluate(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast int64 to string is not supported\n\t [[node sequential_211/movie_model_29/sequential_210/string_lookup_114/Cast (defined at <ipython-input-276-f4b9da47b25b>:30) ]] [Op:__inference_train_function_398809]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_211/movie_model_29/sequential_210/string_lookup_114/Cast:\n IteratorGetNext (defined at <ipython-input-294-438035174cc8>:4)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p90vFk8LvJXp"
   },
   "source": [
    "This gives us a baseline top-100 accuracy of around 0.2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjJ1anzuLXgN"
   },
   "source": [
    "### Capturing time dynamics with time features\n",
    "\n",
    "Do the result change if we add time features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T12:14:28.107207Z",
     "iopub.status.busy": "2022-01-28T12:14:28.106140Z",
     "iopub.status.idle": "2022-01-28T12:15:11.922077Z",
     "shell.execute_reply": "2022-01-28T12:15:11.922542Z"
    },
    "id": "11qAr5gGMUxE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:mask_value is deprecated, use mask_token instead.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'args_9:0' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'args_11:0' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'args_10:0' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'args_4:0' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'args_7:0' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'args_6:0' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'args_5:0' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'args_3:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=int64>, 'price': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=int64>, 'price': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 60s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0031 - factorized_top_k/top_10_categorical_accuracy: 0.0044 - factorized_top_k/top_50_categorical_accuracy: 0.0105 - factorized_top_k/top_100_categorical_accuracy: 0.0157 - loss: 19832.5668 - regularization_loss: 0.0000e+00 - total_loss: 19832.5668\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0091 - factorized_top_k/top_10_categorical_accuracy: 0.0165 - factorized_top_k/top_50_categorical_accuracy: 0.0516 - factorized_top_k/top_100_categorical_accuracy: 0.0795 - loss: 13413.3423 - regularization_loss: 0.0000e+00 - total_loss: 13413.3423\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0068 - factorized_top_k/top_5_categorical_accuracy: 0.0471 - factorized_top_k/top_10_categorical_accuracy: 0.0756 - factorized_top_k/top_50_categorical_accuracy: 0.1800 - factorized_top_k/top_100_categorical_accuracy: 0.2430 - loss: 11650.8844 - regularization_loss: 0.0000e+00 - total_loss: 11650.8844\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0253 - factorized_top_k/top_5_categorical_accuracy: 0.1330 - factorized_top_k/top_10_categorical_accuracy: 0.1865 - factorized_top_k/top_50_categorical_accuracy: 0.3379 - factorized_top_k/top_100_categorical_accuracy: 0.4164 - loss: 9898.3317 - regularization_loss: 0.0000e+00 - total_loss: 9898.3317\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0649 - factorized_top_k/top_5_categorical_accuracy: 0.2297 - factorized_top_k/top_10_categorical_accuracy: 0.2956 - factorized_top_k/top_50_categorical_accuracy: 0.4703 - factorized_top_k/top_100_categorical_accuracy: 0.5529 - loss: 8359.3946 - regularization_loss: 0.0000e+00 - total_loss: 8359.3946\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1003 - factorized_top_k/top_5_categorical_accuracy: 0.3045 - factorized_top_k/top_10_categorical_accuracy: 0.3867 - factorized_top_k/top_50_categorical_accuracy: 0.5774 - factorized_top_k/top_100_categorical_accuracy: 0.6567 - loss: 7204.0647 - regularization_loss: 0.0000e+00 - total_loss: 7204.0647\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1265 - factorized_top_k/top_5_categorical_accuracy: 0.3683 - factorized_top_k/top_10_categorical_accuracy: 0.4606 - factorized_top_k/top_50_categorical_accuracy: 0.6554 - factorized_top_k/top_100_categorical_accuracy: 0.7302 - loss: 6368.2246 - regularization_loss: 0.0000e+00 - total_loss: 6368.2246\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1439 - factorized_top_k/top_5_categorical_accuracy: 0.4206 - factorized_top_k/top_10_categorical_accuracy: 0.5212 - factorized_top_k/top_50_categorical_accuracy: 0.7167 - factorized_top_k/top_100_categorical_accuracy: 0.7851 - loss: 5744.3911 - regularization_loss: 0.0000e+00 - total_loss: 5744.3911\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1540 - factorized_top_k/top_5_categorical_accuracy: 0.4627 - factorized_top_k/top_10_categorical_accuracy: 0.5700 - factorized_top_k/top_50_categorical_accuracy: 0.7600 - factorized_top_k/top_100_categorical_accuracy: 0.8215 - loss: 5273.0663 - regularization_loss: 0.0000e+00 - total_loss: 5273.0663\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1617 - factorized_top_k/top_5_categorical_accuracy: 0.4989 - factorized_top_k/top_10_categorical_accuracy: 0.6095 - factorized_top_k/top_50_categorical_accuracy: 0.7961 - factorized_top_k/top_100_categorical_accuracy: 0.8526 - loss: 4898.5189 - regularization_loss: 0.0000e+00 - total_loss: 4898.5189\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1668 - factorized_top_k/top_5_categorical_accuracy: 0.5288 - factorized_top_k/top_10_categorical_accuracy: 0.6437 - factorized_top_k/top_50_categorical_accuracy: 0.8238 - factorized_top_k/top_100_categorical_accuracy: 0.8742 - loss: 4606.3156 - regularization_loss: 0.0000e+00 - total_loss: 4606.3156\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1709 - factorized_top_k/top_5_categorical_accuracy: 0.5511 - factorized_top_k/top_10_categorical_accuracy: 0.6710 - factorized_top_k/top_50_categorical_accuracy: 0.8463 - factorized_top_k/top_100_categorical_accuracy: 0.8923 - loss: 4352.1540 - regularization_loss: 0.0000e+00 - total_loss: 4352.1540\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1761 - factorized_top_k/top_5_categorical_accuracy: 0.5751 - factorized_top_k/top_10_categorical_accuracy: 0.6969 - factorized_top_k/top_50_categorical_accuracy: 0.8647 - factorized_top_k/top_100_categorical_accuracy: 0.9075 - loss: 4131.7250 - regularization_loss: 0.0000e+00 - total_loss: 4131.7250\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1769 - factorized_top_k/top_5_categorical_accuracy: 0.5939 - factorized_top_k/top_10_categorical_accuracy: 0.7197 - factorized_top_k/top_50_categorical_accuracy: 0.8816 - factorized_top_k/top_100_categorical_accuracy: 0.9195 - loss: 3959.6978 - regularization_loss: 0.0000e+00 - total_loss: 3959.6978\n",
      "Epoch 15/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1803 - factorized_top_k/top_5_categorical_accuracy: 0.6105 - factorized_top_k/top_10_categorical_accuracy: 0.7378 - factorized_top_k/top_50_categorical_accuracy: 0.8937 - factorized_top_k/top_100_categorical_accuracy: 0.9290 - loss: 3803.7859 - regularization_loss: 0.0000e+00 - total_loss: 3803.7859\n",
      "Epoch 16/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1815 - factorized_top_k/top_5_categorical_accuracy: 0.6251 - factorized_top_k/top_10_categorical_accuracy: 0.7558 - factorized_top_k/top_50_categorical_accuracy: 0.9058 - factorized_top_k/top_100_categorical_accuracy: 0.9363 - loss: 3665.6328 - regularization_loss: 0.0000e+00 - total_loss: 3665.6328\n",
      "Epoch 17/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1819 - factorized_top_k/top_5_categorical_accuracy: 0.6395 - factorized_top_k/top_10_categorical_accuracy: 0.7706 - factorized_top_k/top_50_categorical_accuracy: 0.9153 - factorized_top_k/top_100_categorical_accuracy: 0.9437 - loss: 3552.3233 - regularization_loss: 0.0000e+00 - total_loss: 3552.3233\n",
      "Epoch 18/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1836 - factorized_top_k/top_5_categorical_accuracy: 0.6507 - factorized_top_k/top_10_categorical_accuracy: 0.7848 - factorized_top_k/top_50_categorical_accuracy: 0.9227 - factorized_top_k/top_100_categorical_accuracy: 0.9502 - loss: 3435.6191 - regularization_loss: 0.0000e+00 - total_loss: 3435.6191\n",
      "Epoch 19/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1849 - factorized_top_k/top_5_categorical_accuracy: 0.6617 - factorized_top_k/top_10_categorical_accuracy: 0.7968 - factorized_top_k/top_50_categorical_accuracy: 0.9295 - factorized_top_k/top_100_categorical_accuracy: 0.9543 - loss: 3347.6055 - regularization_loss: 0.0000e+00 - total_loss: 3347.6055\n",
      "Epoch 20/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1854 - factorized_top_k/top_5_categorical_accuracy: 0.6717 - factorized_top_k/top_10_categorical_accuracy: 0.8075 - factorized_top_k/top_50_categorical_accuracy: 0.9348 - factorized_top_k/top_100_categorical_accuracy: 0.9588 - loss: 3261.2008 - regularization_loss: 0.0000e+00 - total_loss: 3261.2008\n",
      "Epoch 21/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1879 - factorized_top_k/top_5_categorical_accuracy: 0.6822 - factorized_top_k/top_10_categorical_accuracy: 0.8202 - factorized_top_k/top_50_categorical_accuracy: 0.9411 - factorized_top_k/top_100_categorical_accuracy: 0.9628 - loss: 3187.4926 - regularization_loss: 0.0000e+00 - total_loss: 3187.4926\n",
      "Epoch 22/30\n",
      "40/40 [==============================] - 58s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1855 - factorized_top_k/top_5_categorical_accuracy: 0.6898 - factorized_top_k/top_10_categorical_accuracy: 0.8271 - factorized_top_k/top_50_categorical_accuracy: 0.9455 - factorized_top_k/top_100_categorical_accuracy: 0.9660 - loss: 3116.1770 - regularization_loss: 0.0000e+00 - total_loss: 3116.1770\n",
      "Epoch 23/30\n",
      "40/40 [==============================] - 58s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1857 - factorized_top_k/top_5_categorical_accuracy: 0.6987 - factorized_top_k/top_10_categorical_accuracy: 0.8355 - factorized_top_k/top_50_categorical_accuracy: 0.9496 - factorized_top_k/top_100_categorical_accuracy: 0.9689 - loss: 3048.7117 - regularization_loss: 0.0000e+00 - total_loss: 3048.7117\n",
      "Epoch 24/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1869 - factorized_top_k/top_5_categorical_accuracy: 0.7059 - factorized_top_k/top_10_categorical_accuracy: 0.8446 - factorized_top_k/top_50_categorical_accuracy: 0.9536 - factorized_top_k/top_100_categorical_accuracy: 0.9715 - loss: 3005.2292 - regularization_loss: 0.0000e+00 - total_loss: 3005.2292\n",
      "Epoch 25/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1872 - factorized_top_k/top_5_categorical_accuracy: 0.7124 - factorized_top_k/top_10_categorical_accuracy: 0.8511 - factorized_top_k/top_50_categorical_accuracy: 0.9574 - factorized_top_k/top_100_categorical_accuracy: 0.9741 - loss: 2947.8016 - regularization_loss: 0.0000e+00 - total_loss: 2947.8016\n",
      "Epoch 26/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1874 - factorized_top_k/top_5_categorical_accuracy: 0.7195 - factorized_top_k/top_10_categorical_accuracy: 0.8583 - factorized_top_k/top_50_categorical_accuracy: 0.9603 - factorized_top_k/top_100_categorical_accuracy: 0.9760 - loss: 2902.9760 - regularization_loss: 0.0000e+00 - total_loss: 2902.9760\n",
      "Epoch 27/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1887 - factorized_top_k/top_5_categorical_accuracy: 0.7260 - factorized_top_k/top_10_categorical_accuracy: 0.8630 - factorized_top_k/top_50_categorical_accuracy: 0.9628 - factorized_top_k/top_100_categorical_accuracy: 0.9773 - loss: 2860.5391 - regularization_loss: 0.0000e+00 - total_loss: 2860.5391\n",
      "Epoch 28/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1859 - factorized_top_k/top_5_categorical_accuracy: 0.7311 - factorized_top_k/top_10_categorical_accuracy: 0.8698 - factorized_top_k/top_50_categorical_accuracy: 0.9652 - factorized_top_k/top_100_categorical_accuracy: 0.9793 - loss: 2820.2493 - regularization_loss: 0.0000e+00 - total_loss: 2820.2493\n",
      "Epoch 29/30\n",
      "40/40 [==============================] - 58s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1865 - factorized_top_k/top_5_categorical_accuracy: 0.7356 - factorized_top_k/top_10_categorical_accuracy: 0.8742 - factorized_top_k/top_50_categorical_accuracy: 0.9674 - factorized_top_k/top_100_categorical_accuracy: 0.9806 - loss: 2777.1607 - regularization_loss: 0.0000e+00 - total_loss: 2777.1607\n",
      "Epoch 30/30\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.1866 - factorized_top_k/top_5_categorical_accuracy: 0.7411 - factorized_top_k/top_10_categorical_accuracy: 0.8790 - factorized_top_k/top_50_categorical_accuracy: 0.9694 - factorized_top_k/top_100_categorical_accuracy: 0.9819 - loss: 2737.1997 - regularization_loss: 0.0000e+00 - total_loss: 2737.1997\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=int64>, 'price': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 59s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.2480 - factorized_top_k/top_5_categorical_accuracy: 0.8118 - factorized_top_k/top_10_categorical_accuracy: 0.9149 - factorized_top_k/top_50_categorical_accuracy: 0.9773 - factorized_top_k/top_100_categorical_accuracy: 0.9866 - loss: 2353.3182 - regularization_loss: 0.0000e+00 - total_loss: 2353.3182\n",
      "5/5 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.0188 - factorized_top_k/top_10_categorical_accuracy: 0.0343 - factorized_top_k/top_50_categorical_accuracy: 0.0892 - factorized_top_k/top_100_categorical_accuracy: 0.1298 - loss: 62254.1022 - regularization_loss: 0.0000e+00 - total_loss: 62254.1022\n",
      "Top-100 accuracy (train): 0.99.\n",
      "Top-100 accuracy (test): 0.13.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(use_timestamps=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=30)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "    \n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'args_9:0' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'args_11:0' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'args_10:0' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'args_4:0' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'args_7:0' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'args_6:0' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'args_5:0' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'args_3:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'args_9:0' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'args_11:0' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'args_10:0' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'args_4:0' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'args_7:0' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'args_6:0' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'args_5:0' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'args_3:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=int64>, 'price': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 't_dat': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=int64>, 'price': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>, 'age_group': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_recommenders/tasks/retrieval.py:132 call  *\n        scores = tf.linalg.matmul(\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3655 matmul\n        a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:5714 mat_mul\n        name=name)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 130 and 416 for '{{node retrieval_8/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true](sequential_152/user_model_12/concat, sequential_166/movie_model_11/concat)' with input shapes: [?,130], [?,416].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-68085ab6feac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m train_accuracy = model.evaluate(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_recommenders/tasks/retrieval.py:132 call  *\n        scores = tf.linalg.matmul(\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3655 matmul\n        a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:5714 mat_mul\n        name=name)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 130 and 416 for '{{node retrieval_8/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true](sequential_152/user_model_12/concat, sequential_166/movie_model_11/concat)' with input shapes: [?,130], [?,416].\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(use_timestamps=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=10)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "    \n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHnzYfQrOj8I"
   },
   "source": [
    "This is quite a bit better: not only is the training accuracy much higher, but the test accuracy is also substantially improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.query_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'args_9:0' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'args_11:0' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'args_10:0' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'args_4:0' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'args_7:0' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'args_6:0' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'args_5:0' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'args_3:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'prod_name': <tf.Tensor 'args_9:0' shape=(None,) dtype=string>, 'product_type_name': <tf.Tensor 'args_11:0' shape=(None,) dtype=string>, 'product_group_name': <tf.Tensor 'args_10:0' shape=(None,) dtype=string>, 'graphical_appearance_name': <tf.Tensor 'args_4:0' shape=(None,) dtype=string>, 'colour_group_name': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>, 'perceived_colour_value_name': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'perceived_colour_master_name': <tf.Tensor 'args_7:0' shape=(None,) dtype=string>, 'department_name': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'index_name': <tf.Tensor 'args_6:0' shape=(None,) dtype=string>, 'index_group_name': <tf.Tensor 'args_5:0' shape=(None,) dtype=string>, 'section_name': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>, 'garment_group_name': <tf.Tensor 'args_3:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7f296831d390>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scann_index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((items.batch(128).map(lambda x: x['article_id']), items.batch(128).map(model.candidate_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'00018385675844f7a6babbed41b5655b5727fb16483b6ea51d5798a6ab947344',\n",
       "       b'00019d6c20e0fbb551af18c57149af4707ec016bb0decdf064cdae15ab1569a8',\n",
       "       b'000253f6914890557a88d0b91288ce85fae9332dac43ee5445c33e3891df6fd3',\n",
       "       ...,\n",
       "       b'ffff4c4e8b57b633c1ddf8fbd53db16b962cf831baf9ed67c6a53d86e167a35b',\n",
       "       b'ffff8f9ecdce722b5bab97fff68a6d1866492209bfe5242c50d2a10a652fb5ef',\n",
       "       b'ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e4747568cac33e8c541831'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'customer_id': b'00018385675844f7a6babbed41b5655b5727fb16483b6ea51d5798a6ab947344',\n",
       "  'age_group': 4,\n",
       "  'article_id': b'0535455002',\n",
       "  'rating': 1,\n",
       "  'price': 0,\n",
       "  't_dat': 99,\n",
       "  'prod_name': b'Lastday',\n",
       "  'product_type_name': b'Blouse',\n",
       "  'product_group_name': b'Garment Upper body',\n",
       "  'graphical_appearance_name': b'Jacquard',\n",
       "  'colour_group_name': b'Dark Red',\n",
       "  'perceived_colour_value_name': b'Dark',\n",
       "  'perceived_colour_master_name': b'Orange',\n",
       "  'department_name': b'Blouse',\n",
       "  'index_name': b'Ladieswear',\n",
       "  'index_group_name': b'Ladieswear',\n",
       "  'section_name': b'Womens Everyday Collection',\n",
       "  'garment_group_name': b'Blouses'}]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(interactions.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_id', 'age_group', 'article_id', 'rating', 'price', 't_dat', 'prod_name', 'product_type_name', 'product_group_name', 'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name', 'index_name', 'index_group_name', 'section_name', 'garment_group_name']\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'01e5bd53e72a6bc2c923fa646c41d2250cee46d9820a143c5ca8f1e2ea9fdff2',\n",
      "       b'0cc663c22bc8b0a52bf5aa5948f76b43987b382e5347b7b8bed952173e02b2de',\n",
      "       b'07c0075ab098b0807b511e2e44abe0cf245feb61527cb6191dd8f83a487a89e5'],\n",
      "      dtype=object)>, 'age_group': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 1, 1])>, 'article_id': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'0488697002', b'0714790008', b'0685284002'], dtype=object)>, 'rating': <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 2], dtype=int32)>, 'price': <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 0], dtype=int32)>, 't_dat': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([75, 52, 98])>, 'prod_name': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'Nohar Sneaker', b'Mom HW Ankle Consc', b'Bowy skirt'],\n",
      "      dtype=object)>, 'product_type_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Sneakers', b'Trousers', b'Skirt'], dtype=object)>, 'product_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'Shoes', b'Garment Lower body', b'Garment Lower body'],\n",
      "      dtype=object)>, 'graphical_appearance_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Solid', b'Denim', b'Check'], dtype=object)>, 'colour_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Beige', b'Light Blue', b'Light Beige'], dtype=object)>, 'perceived_colour_value_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Dusty Light', b'Dusty Light', b'Dusty Light'], dtype=object)>, 'perceived_colour_master_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Mole', b'Blue', b'Beige'], dtype=object)>, 'department_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Shoes', b'Denim Trousers', b'Skirt'], dtype=object)>, 'index_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Menswear', b'Divided', b'Ladieswear'], dtype=object)>, 'index_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Menswear', b'Divided', b'Ladieswear'], dtype=object)>, 'section_name': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'Men Shoes', b'Ladies Denim', b'Womens Everyday Collection'],\n",
      "      dtype=object)>, 'garment_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Shoes', b'Trousers Denim', b'Skirts'], dtype=object)>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'01e5bd53e72a6bc2c923fa646c41d2250cee46d9820a143c5ca8f1e2ea9fdff2',\n",
      "       b'0cc663c22bc8b0a52bf5aa5948f76b43987b382e5347b7b8bed952173e02b2de',\n",
      "       b'07c0075ab098b0807b511e2e44abe0cf245feb61527cb6191dd8f83a487a89e5'],\n",
      "      dtype=object)>, 'age_group': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 1, 1])>, 'article_id': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'0488697002', b'0714790008', b'0685284002'], dtype=object)>, 'rating': <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 2], dtype=int32)>, 'price': <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 0], dtype=int32)>, 't_dat': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([75, 52, 98])>, 'prod_name': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'Nohar Sneaker', b'Mom HW Ankle Consc', b'Bowy skirt'],\n",
      "      dtype=object)>, 'product_type_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Sneakers', b'Trousers', b'Skirt'], dtype=object)>, 'product_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'Shoes', b'Garment Lower body', b'Garment Lower body'],\n",
      "      dtype=object)>, 'graphical_appearance_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Solid', b'Denim', b'Check'], dtype=object)>, 'colour_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Beige', b'Light Blue', b'Light Beige'], dtype=object)>, 'perceived_colour_value_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Dusty Light', b'Dusty Light', b'Dusty Light'], dtype=object)>, 'perceived_colour_master_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Mole', b'Blue', b'Beige'], dtype=object)>, 'department_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Shoes', b'Denim Trousers', b'Skirt'], dtype=object)>, 'index_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Menswear', b'Divided', b'Ladieswear'], dtype=object)>, 'index_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Menswear', b'Divided', b'Ladieswear'], dtype=object)>, 'section_name': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b'Men Shoes', b'Ladies Denim', b'Womens Everyday Collection'],\n",
      "      dtype=object)>, 'garment_group_name': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Shoes', b'Trousers Denim', b'Skirts'], dtype=object)>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recommendations: [[b'0617249020', b'0617245003', b'0802087001', b'0680263013', b'0718086002'], [b'0677848008', b'0732412002', b'0739953003', b'0270382004', b'0699867001'], [b'0529008010', b'0561814002', b'0687036007', b'0631837001', b'0251510001']]\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations.\n",
    "\n",
    "for row in test.batch(3).take(1):\n",
    "    print(list(row))\n",
    "    print(f\"Best recommendations: {scann_index(row)[1].numpy()[:, :5].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[b'0663261002', b'0651273003', b'0619464003', b'0695632006', b'0535455002']\n",
    "\n",
    "[b'0535455002', b'0616849012', b'0621020001', b'0626813002',\n",
    "       b'0626813004', b'0651273003', b'0651273004', b'0667916002',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Sequential' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-f3ab04390e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Sequential' object does not support indexing"
     ]
    }
   ],
   "source": [
    "model.query_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lots_of_movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-226-32a265ef053f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorized_top_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScaNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_reordering_candidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m scann.index_from_dataset(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlots_of_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlots_of_movies_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lots_of_movies' is not defined"
     ]
    }
   ],
   "source": [
    "scann = tfrs.layers.factorized_top_k.ScaNN(num_reordering_candidates=100)\n",
    "scann.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB09crfpgBx7"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "This tutorial shows that even simple models can become more accurate when incorporating more features. However, to get the most of your features it's often necessary to build larger, deeper models. Have a look at the [deep retrieval tutorial](deep_recommenders) to explore this in more detail."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "context_features.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
